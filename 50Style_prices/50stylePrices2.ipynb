{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19254b8a",
   "metadata": {},
   "source": [
    "# Webscrapping from https://50style.pl/\n",
    "### Articels and prices from each subpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c7fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "from time import time, sleep\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1421c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of free proxies \n",
    "proxies = [{\"http\": \"95.178.108.89\"},\n",
    "           {\"http\": \"95.178.108.189\"},\n",
    "           {\"http\": \"80.48.119.28\"},\n",
    "           {\"http\": \"192.166.255.200\"},\n",
    "           {\"http\": \"89.174.108.158\"},\n",
    "           {\"http\": \"193.106.231.145\"},\n",
    "           {\"http\": \"91.222.147.56\"},\n",
    "           {\"http\": \"77.65.163.170\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9da4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e57a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_50style(main_url = \"https://50style.pl/\", subpages = ['meskie','damskie', 'dzieciece']):\n",
    "    '''\n",
    "    main_url = main url adress without any subpages\n",
    "    subpages = list of subpages, ie = ['meskie','damskie', 'dzieciece'], to get 'https://50style.pl/dzieciece'\n",
    "    \n",
    "    '''\n",
    "    start = time() # start time\n",
    "    \n",
    "    session = requests.Session()\n",
    "    session.max_redirects = 60\n",
    "    cookies = dict(cookies_are='working')\n",
    "    \n",
    "    # empty dataframe to collect data\n",
    "    pricelist = pd.DataFrame({\"Article\" : [],\n",
    "                 \"Price\" : []})\n",
    "\n",
    "    # iteration through each subpage\n",
    "    for id, subpage in enumerate(subpages):\n",
    "        for n in range(1,100):\n",
    "            \n",
    "            # iterate through each number of subpage\n",
    "            url = main_url + str(subpage) + '?sort=default&limit=180&page=' + str(n) \n",
    "\n",
    "            # get whole structure of data, and avoid getting blocked, by add headers parameter\n",
    "            page = session.get(url, headers = headers,cookies=cookies) \n",
    "\n",
    "            # let parse our web page\n",
    "            soup = BeautifulSoup(page.content)\n",
    "            \n",
    "            # iterate throug all products on one page\n",
    "            for product in soup.find_all(attrs = {'class': 'b-itemList_name'}):\n",
    "                link =\"https://50style.pl\" + product.find('a')['href']\n",
    "\n",
    "                # choose random proxy\n",
    "                proxy = random.choice(proxies)\n",
    "                \n",
    "                page1 = session.get(link, headers = headers,proxies = proxy, timeout = 28,cookies=cookies) \n",
    "                soup1 = BeautifulSoup(page1.content)\n",
    "\n",
    "                index = soup1.find(attrs = {'class': \"m-accordion_productCode\"}).text\n",
    "                price = soup1.find(attrs = {'class': \"price-value\"}).text\n",
    "\n",
    "                pricelist = pricelist.append({'Article' : index,\n",
    "                               'Price' : price},\n",
    "                              ignore_index = True)\n",
    "\n",
    "                # sleep for one seconds after each link to avoid block\n",
    "                sleep(1)\n",
    "\n",
    "            # check if there is another subpage\n",
    "            next_page_no = soup.find(class_='m-pagination').find_all('span')[-1].text.replace('z ',\"\").strip()\n",
    "\n",
    "            if next_page_no == '':\n",
    "                break\n",
    "                \n",
    "            print(\"number of subpage: \", subpage, n)    \n",
    "            # sleep for three seconds to avoid block\n",
    "            sleep(1)\n",
    "\n",
    "    end = time()\n",
    "    print(round(end - start,2), 'calculation time in sec')\n",
    "    \n",
    "    return pricelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "467d3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want only specific brands\n",
    "groups = ['marki/adidas','marki/new-balance','marki/puma','marki/reebok','marki/vans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db09cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subpage:  marki/adidas 1\n"
     ]
    }
   ],
   "source": [
    "scrap_50style(subpages=groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
